{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f78536b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of rows in the maze:  4\n",
      "Enter number of columns in the maze:  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the maze layout row by row (0 = free, 1 = wall):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Row 0:  0 0 1 1\n",
      "Row 1:  0 1 0 0\n",
      "Row 2:  1 0 1 0\n",
      "Row 3:  1 1 0 0\n",
      "Enter start position (row col):  0 0 \n",
      "Enter goal position (row col):  3 3 \n",
      "Enter learning rate alpha (e.g., 0.1):  0.1\n",
      "Enter discount factor gamma (e.g., 0.9):  0.9\n",
      "Enter exploration rate epsilon (e.g., 0.2):  0.2\n",
      "Enter number of episodes for training:  1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m         new_state \u001b[38;5;241m=\u001b[39m state_index(new_pos)\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;66;03m# Q-learning update\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m         Q[state, action_idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m (reward \u001b[38;5;241m+\u001b[39m gamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(Q[new_state]) \u001b[38;5;241m-\u001b[39m Q[state, action_idx])\n\u001b[1;32m     82\u001b[0m         pos \u001b[38;5;241m=\u001b[39m new_pos\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3047\u001b[0m, in \u001b[0;36m_max_dispatcher\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3043\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m keepdims\n\u001b[1;32m   3044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_ptp(a, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_max_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3048\u001b[0m                     where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[1;32m   3052\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   3055\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rows = int(input(\"Enter number of rows in the maze: \"))\n",
    "cols = int(input(\"Enter number of columns in the maze: \"))\n",
    "\n",
    "print(\"Enter the maze layout row by row (0 = free, 1 = wall):\")\n",
    "maze = []\n",
    "for r in range(rows):\n",
    "    while True:\n",
    "        row = input(f\"Row {r}: \").strip().split()\n",
    "        if len(row) == cols and all(cell in ['0', '1'] for cell in row):\n",
    "            maze.append([int(cell) for cell in row])\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Invalid input. Enter exactly {cols} numbers (0 or 1).\")\n",
    "            \n",
    "maze = np.array(maze)\n",
    "\n",
    "def get_position(prompt):\n",
    "    while True:\n",
    "        try:\n",
    "            pos = tuple(map(int, input(prompt).split()))\n",
    "            if 0 <= pos[0] < rows and 0 <= pos[1] < cols and maze[pos[0], pos[1]] == 0:\n",
    "                return pos\n",
    "            else:\n",
    "                print(\"Position invalid or is a wall.\")\n",
    "        except:\n",
    "            print(\"Enter two integers separated by space.\")\n",
    "\n",
    "start = get_position(\"Enter start position (row col): \")\n",
    "goal = get_position(\"Enter goal position (row col): \")\n",
    "\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "state_size = rows * cols\n",
    "action_size = len(actions)\n",
    "\n",
    "alpha = float(input(\"Enter learning rate alpha (e.g., 0.1): \"))\n",
    "gamma = float(input(\"Enter discount factor gamma (e.g., 0.9): \"))\n",
    "epsilon = float(input(\"Enter exploration rate epsilon (e.g., 0.2): \"))\n",
    "episodes = int(input(\"Enter number of episodes for training: \"))\n",
    "\n",
    "def state_index(pos):\n",
    "    return pos[0] * cols + pos[1]\n",
    "\n",
    "def is_valid(pos):\n",
    "    r, c = pos\n",
    "    return 0 <= r < rows and 0 <= c < cols and maze[r, c] == 0\n",
    "\n",
    "def step(pos, action):\n",
    "    r, c = pos\n",
    "    if action == 'up': r -= 1\n",
    "    elif action == 'down': r += 1\n",
    "    elif action == 'left': c -= 1\n",
    "    elif action == 'right': c += 1\n",
    "\n",
    "    new_pos = (r, c)\n",
    "    if not is_valid(new_pos):\n",
    "        new_pos = pos\n",
    "    reward = 10 if new_pos == goal else -1\n",
    "    return new_pos, reward\n",
    "\n",
    "Q = np.zeros((state_size, action_size))\n",
    "\n",
    "for ep in range(episodes):\n",
    "    pos = start\n",
    "    while pos != goal:\n",
    "        state = state_index(pos)\n",
    "        # Epsilon-greedy action\n",
    "        if random.random() < epsilon:\n",
    "            action_idx = random.randint(0, action_size - 1)\n",
    "        else:\n",
    "            action_idx = np.argmax(Q[state])\n",
    "        action = actions[action_idx]\n",
    "\n",
    "        new_pos, reward = step(pos, action)\n",
    "        new_state = state_index(new_pos)\n",
    "\n",
    "        # Q-learning update\n",
    "        Q[state, action_idx] += alpha * (reward + gamma * np.max(Q[new_state]) - Q[state, action_idx])\n",
    "\n",
    "        pos = new_pos\n",
    "\n",
    "print(\"Training completed!\")\n",
    "\n",
    "pos = start\n",
    "path = [pos]\n",
    "while pos != goal:\n",
    "    state = state_index(pos)\n",
    "    action_idx = np.argmax(Q[state])\n",
    "    action = actions[action_idx]\n",
    "    pos, _ = step(pos, action)\n",
    "    path.append(pos)\n",
    "\n",
    "def print_maze_path(maze, path, goal):\n",
    "    maze_vis = maze.astype(str)\n",
    "    for r, c in path:\n",
    "        maze_vis[r, c] = '*'\n",
    "    maze_vis[goal] = 'G'\n",
    "    print(\"\\nMaze with optimal path:\")\n",
    "    for row in maze_vis:\n",
    "        print(' '.join(row))\n",
    "\n",
    "print(\"Optimal path found by the agent:\")\n",
    "print(path)\n",
    "print_maze_path(maze, path, goal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca0acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
